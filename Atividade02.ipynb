{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Atividade02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyONJLOmGm+LhH8EUtVNcI+h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArturHugo/PLN-2022-1/blob/main/Atividade02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Atividade 02 - Preprocessamento de texto\n",
        "Grupo:\n",
        "\n",
        "- Artur Hugo cunha Pereira, 180030400\n",
        "- Gabriel da Silva Corvino Nogueira, 180113330 \n"
      ],
      "metadata": {
        "id": "QOHZl0bgq7bx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygAmwSR-q3ty"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/viniciusrpb/cic0269_natural_language_processing/main/corpus_tweets/twitter-2013train-A.txt', sep='\\t', names=['id', 'sentiment', 'tweet'])\n",
        "df.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BO3ckKPrXWB",
        "outputId": "3ca2fdb2-413b-4e07-a037-23593cc47efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[264183816548130816, 'positive',\n",
              "        'Gas by my house hit $3.39!!!! I\\\\u2019m going to Chapel Hill on Sat. :)'],\n",
              "       [263405084770172928, 'negative',\n",
              "        'Theo Walcott is still shit\\\\u002c watch Rafa and Johnny deal with him on Saturday.'],\n",
              "       [262163168678248449, 'negative',\n",
              "        'its not that I\\\\u2019m a GSP fan\\\\u002c i just hate Nick Diaz. can\\\\u2019t wait for february.'],\n",
              "       ...,\n",
              "       [100259220338905089, 'neutral',\n",
              "        'All Blue and White fam, we r meeting at Golden Corral for dinner tonight at 6pm....'],\n",
              "       [104230318525001729, 'positive',\n",
              "        '@DariusButler28   Have a great game agaist Tampa Bay tonight.'],\n",
              "       [100461938533863424, 'negative',\n",
              "        \"I'm pisseeedddd that I missed Kid Cudi's show in Dallas, it was trending worldwide that night, &all Im hearing is positive reviews of lolla\"]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_df = df['tweet']\n",
        "tweet_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ6GNQEysoZw",
        "outputId": "dd8b4ca3-ae65-4ef1-ac3d-88d1d044f1f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Gas by my house hit $3.39!!!! I\\u2019m going t...\n",
              "1       Theo Walcott is still shit\\u002c watch Rafa an...\n",
              "2       its not that I\\u2019m a GSP fan\\u002c i just h...\n",
              "3       Iranian general says Israel\\u2019s Iron Dome c...\n",
              "4       Tehran\\u002c Mon Amour: Obama Tried to Establi...\n",
              "                              ...                        \n",
              "9679    RT @MNFootNg It's monday and Monday Night Foot...\n",
              "9680    All I know is the road for that Lomardi start ...\n",
              "9681    All Blue and White fam, we r meeting at Golden...\n",
              "9682    @DariusButler28   Have a great game agaist Tam...\n",
              "9683    I'm pisseeedddd that I missed Kid Cudi's show ...\n",
              "Name: tweet, Length: 9684, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "stemmer = nltk.stem.porter.PorterStemmer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peNleru71Qzl",
        "outputId": "1e8c29ee-0399-4765-f9c6-45f2a65e5d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "def tokenize(string):\n",
        "  # Replace happy emotes: :) , :D , xD , etc.\n",
        "  res = re.sub(r'[:Xx][\\)D]', 'happy', string.lower())\n",
        "  # Replace sad emotes: :( , xC , >:\\ , etc.\n",
        "  res = re.sub(r'>?[:Xx][\\(Cc\\\\\\/]', 'sad', res)\n",
        "  # Split string in unicode characters, user handles, apostrophes, \n",
        "  # dollar sign and punctuation (:, . and ,) followed by white space.\n",
        "  res = re.split(r'\\'|@\\w+|\\\\u[0-9a-f]{4}|[\\.:,]\\s|!|\\$', res)\n",
        "  # Runs through nltk tokenizer to finish tokenization\n",
        "  res = nltk.tokenize.word_tokenize(' '.join(res))\n",
        "  return res\n",
        "\n",
        "def filter_stopwords(word_array, stop_list):\n",
        "  # If word is in stop_list it is filtered out\n",
        "  res = [word for word in word_array if word not in stop_list]\n",
        "  return res"
      ],
      "metadata": {
        "id": "fwtJIR0Rwl0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing\n",
        "tweet_df = tweet_df.apply(tokenize)\n",
        "tweet_df.values[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3-xX02PwNnW",
        "outputId": "49858100-a1ac-4728-f584-c8813598f30b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gas',\n",
              " 'by',\n",
              " 'my',\n",
              " 'house',\n",
              " 'hit',\n",
              " '3.39',\n",
              " 'i',\n",
              " 'm',\n",
              " 'going',\n",
              " 'to',\n",
              " 'chapel',\n",
              " 'hill',\n",
              " 'on',\n",
              " 'sat',\n",
              " 'happy']"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop words\n",
        "stop_list = [element[0] for element in pd.read_csv('https://raw.githubusercontent.com/ravikiranj/twitter-sentiment-analyzer/master/data/feature_list/stopwords.txt', header=None).values]\n",
        "stop_list.extend(['rt', ',']) # Additional stopwords\n",
        "tweet_df = tweet_df.apply(lambda tweet: filter_stopwords(tweet, stop_list))\n",
        "tweet_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEsud-pizuM3",
        "outputId": "0d8bbc22-b6a4-42e5-9200-e8bfd1e4ff18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [gas, house, hit, 3.39, chapel, hill, sat, happy]\n",
              "1       [theo, walcott, shit, watch, rafa, johnny, dea...\n",
              "2         [gsp, fan, hate, nick, diaz, wait, february, .]\n",
              "3       [iranian, israel, iron, dome, deal, missiles, ...\n",
              "4       [tehran, mon, amour, obama, tried, establish, ...\n",
              "                              ...                        \n",
              "9679    [monday, monday, night, football, mind, love, ...\n",
              "9680    [road, lomardi, start, tonight, set, record, p...\n",
              "9681    [blue, white, fam, meeting, golden, corral, di...\n",
              "9682               [game, agaist, tampa, bay, tonight, .]\n",
              "9683    [pisseeedddd, missed, kid, cudi, dallas, trend...\n",
              "Name: tweet, Length: 9684, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "tweet_df = tweet_df.apply(lambda tweet: [stemmer.stem(word) for word in tweet])\n",
        "tweet_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFJLDtSg4ZDt",
        "outputId": "d573ccd6-3aec-49b3-9e01-282bab7741a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         [ga, hous, hit, 3.39, chapel, hill, sat, happi]\n",
              "1       [theo, walcott, shit, watch, rafa, johnni, dea...\n",
              "2         [gsp, fan, hate, nick, diaz, wait, februari, .]\n",
              "3       [iranian, israel, iron, dome, deal, missil, (,...\n",
              "4       [tehran, mon, amour, obama, tri, establish, ti...\n",
              "                              ...                        \n",
              "9679    [monday, monday, night, footbal, mind, love, f...\n",
              "9680    [road, lomardi, start, tonight, set, record, p...\n",
              "9681    [blue, white, fam, meet, golden, corral, dinne...\n",
              "9682               [game, agaist, tampa, bay, tonight, .]\n",
              "9683    [pisseeedddd, miss, kid, cudi, dalla, trend, w...\n",
              "Name: tweet, Length: 9684, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    }
  ]
}